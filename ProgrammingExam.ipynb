{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a33b4b2b151ff5e03c9bc52feefbc951",
     "grade": false,
     "grade_id": "cell-cbf7bc8ef1cb52b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Programming Exam Instructions\n",
    "\n",
    "- The programming exam is in the form of a Jupyter notebook.\n",
    "- All questions are auto-graded and you have unlimited attempt. \n",
    "- In the Rlab Jupyter notebook,  you should see the exam information and the detailed tasks in text, as well as pieces of code chunks.  Some code chunks were pre-written by your instructor. Others need to be completed by students. \n",
    "- You have to run every single code chunk (including the ones provided by your instructor ) in sequence.  \n",
    "- Code chunks with \"# your code here\" lines  should be replaced by your own code.\n",
    "- There are special code chunks containing \"# Test your code in here\" lines. Those code cells contain code invisible to students, which automatically grades the assignment after the deadline or when a student clicks on  \"Submit Assignment\" button. \n",
    "- You can click on validate button in Jupyter notebook to see if your code passed the test. \n",
    "- Please run each code chunk in a sequence as some codes rely on succesful execution of earlier code chunks\n",
    "- From the time you have started the exam, you will have full **4 hours** to complete the programming exam\n",
    "- You can check your  notes when you take the programming exam\n",
    "- Sharing exam questions or answers on the web, social media platforms or in other outlets is a direct violation of UNT Code of Conduct and UNT Policy of Academic Integrity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "180239b5331754a15ba220365f21a27c",
     "grade": false,
     "grade_id": "cell-d13ba5753f22ae4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Data Preparation\n",
    "In this programming exam, we will use US birth data. Every year, the US releases a large data set containing information on births recorded in the country. We have a random sample of 1,000 cases from the data set released in 2014. There are 13 variables in the dataset:\n",
    "\n",
    "-**fage**: Father's age in years.\n",
    "\n",
    "-**mage**: Mother's age in years.\n",
    "\n",
    "-**mature**: Maturity status of mother.\n",
    "\n",
    "-**weeks**: Length of pregnancy in weeks.\n",
    "\n",
    "-**premie**: Whether the birth was classified as premature (premie) or full-term.\n",
    "\n",
    "-**visits**: Number of hospital visits during pregnancy.\n",
    "\n",
    "-**gained**: Weight gained by mother during pregnancy in pounds.\n",
    "\n",
    "-**weight**: Weight of the baby at birth in pounds.\n",
    "\n",
    "-**lowbirthweight**: Whether baby was classified as low birthweight (low) or not (not low).\n",
    "\n",
    "-**sex**: Sex of the baby, female or male.\n",
    "\n",
    "-**habit**: Status of the mother as a nonsmoker or a smoker.\n",
    "\n",
    "-**marital**: Whether mother is married or not married at birth.\n",
    "\n",
    "-**whitemom**: Whether mom is white or not white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16b39dd8f72dc3ac8570ac60059786f8",
     "grade": false,
     "grade_id": "cell-89b9958ca33b343d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fage            mage               mature        weeks      \n",
       " Min.   :15.00   Min.   :14.00   mature mom :159   Min.   :21.00  \n",
       " 1st Qu.:26.00   1st Qu.:24.00   younger mom:841   1st Qu.:38.00  \n",
       " Median :31.00   Median :28.00                     Median :39.00  \n",
       " Mean   :31.13   Mean   :28.45                     Mean   :38.67  \n",
       " 3rd Qu.:35.00   3rd Qu.:33.00                     3rd Qu.:40.00  \n",
       " Max.   :85.00   Max.   :47.00                     Max.   :46.00  \n",
       " NA's   :114                                                      \n",
       "       premie        visits          gained          weight      \n",
       " full term:876   Min.   : 0.00   Min.   : 0.00   Min.   : 0.750  \n",
       " premie   :124   1st Qu.: 9.00   1st Qu.:20.00   1st Qu.: 6.545  \n",
       "                 Median :12.00   Median :30.00   Median : 7.310  \n",
       "                 Mean   :11.35   Mean   :30.43   Mean   : 7.198  \n",
       "                 3rd Qu.:14.00   3rd Qu.:38.00   3rd Qu.: 8.000  \n",
       "                 Max.   :30.00   Max.   :98.00   Max.   :10.620  \n",
       "                 NA's   :56      NA's   :42                      \n",
       " lowbirthweight     sex            habit            marital         whitemom  \n",
       " low    : 81    female:495   nonsmoker:867   married    :594   not white:235  \n",
       " not low:919    male  :505   smoker   :114   not married:406   white    :765  \n",
       "                             NA's     : 19                                    \n",
       "                                                                              \n",
       "                                                                              \n",
       "                                                                              \n",
       "                                                                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#call the packages\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(testthat)\n",
    "library(caret)\n",
    "library(recipes)\n",
    "# call the birth data\n",
    "birth<-read.csv(\"birth.csv\", header=TRUE)\n",
    "summary(birth)\n",
    "library(class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1bbd2c5250a6e897c81530dc90c1794d",
     "grade": false,
     "grade_id": "cell-f5386a1ad8615bad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# TASK 1: Data Cleaning  [30 points]\n",
    "In this task, you will work with the **birth** data\n",
    "\n",
    "In **birth** data, complete the following tasks:\n",
    "\n",
    "- replace missing values in **fage** variable with **15**  (**fage** will take the value of 15 when missing)  \n",
    "- replace missing values in **visits** variable with **11** (**visits** will take the value of 11 when missing)  \n",
    "- drop observations from **birth** data when **habit** variable has a missing value (drop all rows when **habit** is  missing )\n",
    "- drop observations from **birth** data when **gained** variable has a missing value (drop all rows when **gained** is  missing)\n",
    "- rename  **sex** to **gender** (variable name **sex** will be changed to **gender**)\n",
    "\n",
    "-NOTE: We worked on a similar problem in RLab1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb9faa832fe87394bb5179cecbb68d71",
     "grade": false,
     "grade_id": "cell-31633fa85a412855",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Task #1: Prepare the data. \n",
    "# Your codes will pass the test if you complete all the data claenining tasks\n",
    "birth <-read.csv(\"birth.csv\", header=TRUE)\n",
    "# your code here\n",
    "\n",
    "birth$fage[which(is.na(birth$fage))] = 15\n",
    "birth$visits[which(is.na(birth$visits))] = 11\n",
    "\n",
    "birth <- na.omit(birth)\n",
    "\n",
    "birth <- rename(birth, gender = sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dffe9d752b5e59c3c104f8bccc0c78ef",
     "grade": true,
     "grade_id": "cell-afbde33590dc896d",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Passed!\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test your code in here\n",
    "### BEGIN HIDDEN TEST\n",
    "\n",
    "test_that(\"Check the model summary\", {\n",
    "    expect_equal(round(mean(birth$fage),3),29.349)\n",
    "    expect_equal(  IQR(birth$visits),3)\n",
    "    expect_equal( sum(is.na(birth$habit)),0)\n",
    "    expect_equal( sum(is.na(birth$gained)),0)\n",
    "    expect_equal( dim(birth)[1],941)\n",
    "})\n",
    "\n",
    "\n",
    "print(\"Passed!\")\n",
    "\n",
    "### END HIDDEN TEST\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29dde626462554d34132472663445ce4",
     "grade": false,
     "grade_id": "cell-4b3773f3b0a152a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2:  modeling lowbirthweight with logistic regression\n",
    "- In this part we will work with **birth1** data. **birth1** data is a subset of **birth** data with complete cases. There are 794 rows and 13 columns. Students can get full credit from Task 2 even if they can't complete Task 1.\n",
    "- **birth1** is split into **birth_train** and **birth_test** datasets by using the **createDataPartition()** function in **caret** package.\n",
    "\n",
    "In this part, your job is to use logistic regression to model **lowbirthweight** by using the all predictors in the dataset.\n",
    "Run the following code chunk first. The codes below call the original data, drop cases where we have a missing value, name the dataset as **birth1**, then by using the **createDataPartition** function in **caret** package, it splits data into **birth_train** and **birth_test**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfde8227392a41198fbcbc8d93ecb640",
     "grade": false,
     "grade_id": "cell-d9fca49771632237",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this code chunk first\n",
    "raw<-read.csv(\"birth.csv\", header=TRUE)    # get the original birth data\n",
    "birth1<-raw%>%                             # drop rows with missing values and name the dataset as birth1\n",
    "filter(complete.cases(.))\n",
    "\n",
    "set.seed(4230) #set the seed function\n",
    "index_data <- createDataPartition(birth1$lowbirthweight, p = 0.7,\n",
    "list = FALSE)\n",
    "birth_train <- birth1[index_data, ]\n",
    "birth_test <- birth1[-index_data, ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f62c32c74f569204954788eb73517bf",
     "grade": false,
     "grade_id": "cell-31bc520dab8921a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 2 [30 points]\n",
    "- By using the **birth_train** data, use the **glm()** function in R to estimate **lowbirthweight** with logistic regression by using all the predictors in the dataset and call your model as **model_logistic**. Use **set.seed(4230)**. If you get the warning message: “glm.fit: algorithm did not converge”, just ignore the warning. \n",
    "- Calculate the predicted probability of **lowbirthweight** in  **birth_test** by using the **model_logistic** model. Name your findings as **logistic_predict** . Use **set.seed(4230)**.  \n",
    "\n",
    "-NOTE: We worked on a similar problem in RLab2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34e3c3f9f2f993e03ed58097aeb9aab1",
     "grade": false,
     "grade_id": "cell-2c2084ceb8d62d0a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: algorithm did not converge”\n",
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”\n"
     ]
    }
   ],
   "source": [
    "# Task #2: Logistic regression \n",
    "# use set.seed(4230) just  before running glm function\n",
    "# use set.seed(4230) just  before running predict function\n",
    "# You should complete the both tasks to pass this test\n",
    "\n",
    "\n",
    "# your code here\n",
    "set.seed(4230)\n",
    "\n",
    "model_logistic <- glm(lowbirthweight ~ (.), family = \"binomial\", data=birth_train)\n",
    "\n",
    "set.seed(4230)\n",
    "logistic_predict <- predict(model_logistic, birth_test, type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3aa9fce3d1d7bf0dd411bdeef010cf4e",
     "grade": true,
     "grade_id": "cell-29621aff7fad4ff7",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Passed!\"\n"
     ]
    }
   ],
   "source": [
    "# Test your code in here\n",
    "### BEGIN HIDDEN TEST\n",
    "\n",
    "test_that(\"Check the model summary\", {\n",
    "    expect_equal(round(summary(model_logistic)[8][[1]]),293)\n",
    "    expect_equal( round(summary(model_logistic)[7][[1]]),544)\n",
    "    expect_equal( length(logistic_predict),237)\n",
    "    expect_equal( round(mean(logistic_predict), 3),0.904)\n",
    "    expect_equal( round(sum(logistic_predict), 1),214.4)\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "print(\"Passed!\")\n",
    "\n",
    "### END HIDDEN TEST\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee2b4a296fa4f3234f21b27ab818a71e",
     "grade": false,
     "grade_id": "cell-b1b091541c399001",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 3: Modeling lowbirthweight with knn \n",
    "In this part, we will use the k-nearest neighbors (knn) algorithm to classify and predict new observations in **birth_test** with their proximity to k most-similar observations from **birth_train**. \n",
    "\n",
    "\n",
    "The following r chunk code preprocess our data for knn model. By using **recipe** function in **recipes** package, the following code chunk centers and scales numerical features and conducts one-hot encoding on categorical features such that there will be one dummy variable for each group of a categorical variable. The following code chunk stores the pre-processed features data for the training and test sets under **features_train** and **features_test** datasets, respectively. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f17956e81402f5bd6d3edabe828232e0",
     "grade": false,
     "grade_id": "cell-5cb866aa3df2c9a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this code chunk first before moving onto Task 3\n",
    "# some cleaning with the recipe function. Do the pre processing on the birth_train data\n",
    "features_train <- recipe(lowbirthweight  ~ ., data = birth_train) %>%\n",
    "  step_center(all_numeric(), -all_outcomes()) %>%\n",
    "  step_scale(all_numeric(), -all_outcomes())%>%\n",
    "step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%\n",
    "prep(training = birth_train, retain = TRUE) %>%\n",
    "juice() %>%\n",
    "  select(-lowbirthweight)\n",
    "\n",
    "\n",
    "# some cleaning with the recipe function. Do the pre processing on the birth_test data\n",
    "features_test <- recipe(lowbirthweight  ~ ., data = birth_test) %>%\n",
    "  step_center(all_numeric(), -all_outcomes()) %>%\n",
    "  step_scale(all_numeric(), -all_outcomes())%>%\n",
    "step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%\n",
    "prep(training = birth_test, retain = TRUE) %>%\n",
    "juice() %>%\n",
    "  select(-lowbirthweight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "590954086fc70d03bcb61596797406fd",
     "grade": false,
     "grade_id": "cell-dd8453ebaf0e5871",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 3 [30 points]\n",
    "\n",
    "Use the **knn** function in **class** package to predict **lowbirthweight** in the test data with **knn** method when **k=20**. Use the **set.seed(4230)** seed function and name the predicted test data labels as **model_knn**. \n",
    "\n",
    "Please note than knn() function in the class package requires predictors and labels to be entered separately. More specifically, predictors need to be a matrix and the label to be a vector only. \n",
    "\n",
    "NOTE:  We worked on a similar problem in RLab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9bf3f09af50e16260f507106b4207eb",
     "grade": false,
     "grade_id": "cell-4de05a91407ec594",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#  Task 3: knn when k=20\n",
    "# Use set.seed(4230)\n",
    "# your code here\n",
    "\n",
    "y_train <- birth_train$lowbirthweight\n",
    "y_test <- birth_test$lowbirthweight\n",
    "\n",
    "set.seed(4230)\n",
    "model_knn <- knn(train =  features_train,\n",
    "                test =  features_test,\n",
    "                 cl = y_train,\n",
    "                 k = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21cb41d127d4c1f4ff149def9c00830a",
     "grade": true,
     "grade_id": "cell-dabbdb65193b1c30",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Passed!\"\n"
     ]
    }
   ],
   "source": [
    "# Test your code in here\n",
    "### BEGIN HIDDEN TEST\n",
    "\n",
    "class_error = function(actual, predicted) {\n",
    "  mean(actual != predicted)\n",
    "}\n",
    "\n",
    "test_that(\"Check the classification error\", {\n",
    "    expect_equal( round(class_error(birth_test$lowbirthweight,model_knn), 2),0.06)})\n",
    "        \n",
    "print(\"Passed!\")\n",
    "\n",
    "### END HIDDEN TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f3c0dd7b819380caa8aeaecb3d56f11",
     "grade": false,
     "grade_id": "cell-1a7f2657e99e9bd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# Task 4 [10 points]\n",
    "\n",
    "\n",
    "What is the accuracy rate in **model_knn**. Calculate the accuracy rate and name it as **accuracy_model_knn**. Your accuracy calculation should be at least 3 digits to pass the test.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9065676976b8a0357827c64583d7081",
     "grade": false,
     "grade_id": "cell-475e93a9b5b572d7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#  Task 4: calculate the accuracy ratio\n",
    "\n",
    "# your code here\n",
    "accuracy_table <-table(model_knn, birth_test$lowbirthweight)\n",
    "\n",
    "TP <- 3\n",
    "FP <- 0\n",
    "TN <- 220\n",
    "FN <- 14\n",
    "\n",
    "accuracy_model_knn <- (TP + TN) / (TN + TP + FN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8da2afb5bf54dd9f2ac4cec2c4dcb3f",
     "grade": true,
     "grade_id": "cell-08d150b81125735e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Passed!\"\n"
     ]
    }
   ],
   "source": [
    "# Test your code in here\n",
    "### BEGIN HIDDEN TEST\n",
    "\n",
    "\n",
    "\n",
    "test_that(\"Check the accuracy  measure\", {\n",
    "    expect_equal( round(round(accuracy_model_knn, 3)^(-1/round(accuracy_model_knn,2)), 3),1.067)})\n",
    "        \n",
    "print(\"Passed!\")\n",
    "\n",
    "### END HIDDEN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
